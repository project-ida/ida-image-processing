{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65aba382-43d2-4144-b366-2d54185d39ad",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "\n",
    "Sometimes the sample axes need to be read in the opposite way to normal, e.g. right to left instead of left to right.\n",
    "\n",
    "If you find the stitched image looks off, then search for the parameters `invertx` and `inverty` in this notebook and change them according to the comments found next to those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f361808-d763-4023-8677-f821177ebc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythondata_folder = r\"/mnt/data/semeds/20250825_sample 10 (eds)/Project 1/h5data\"\n",
    "#pythondata_folder = r\"/mnt/data/semeds/20250826 # 10 after (eds)/Project 1/h5pythondata\"\n",
    "pythondata_folder = r\"/mnt/data/semeds/20241210 Jonah 9 (eds)/Project 1/h5pythondata\"\n",
    "#pythondata_folder = r\"/mnt/data/semeds/20241218 Jonah 10 (eds)/Project 1/h5pythondata\"\n",
    "\n",
    "# pythondata_folder = r\"/media/lenr/Data/semeds/Florian Ti (eds)/h5data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192357a-e6f8-4ac4-a8f6-dfe1f54c2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- user toggles ---\n",
    "invertx = 1   # 0 = normal, 1 = mirror left↔right\n",
    "inverty = 1   # 0 = normal, 1 = mirror top↔bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f4489-36ef-44a3-ac7f-c214d75d4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as w\n",
    "from IPython.display import Javascript, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b653d39-6959-46e4-8faa-6c34789fb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(pythondata_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f602660-7eed-4dc3-9abc-5ca97832cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_RE = re.compile(r\"^\\s*(?P<key>.+?)\\s*:\\s*(?P<val>.+?)\\s*$\")\n",
    "\n",
    "# 1) Add a field to the dataclass\n",
    "@dataclass\n",
    "class SiteRecord:\n",
    "    basename: str\n",
    "    png_path: str\n",
    "    meta_path: str\n",
    "    npz_path: Optional[str] = None        \n",
    "    width_px: Optional[int] = None\n",
    "    height_px: Optional[int] = None\n",
    "    px_x_um: Optional[float] = None\n",
    "    px_y_um: Optional[float] = None\n",
    "    tile_w_um: Optional[float] = None\n",
    "    tile_h_um: Optional[float] = None\n",
    "    stage_x_um: Optional[float] = None\n",
    "    stage_y_um: Optional[float] = None\n",
    "    stage_z_um: Optional[float] = None\n",
    "\n",
    "def parse_metadata_txt(path: Path) -> Dict[str, str]:\n",
    "    out: Dict[str, str] = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        m = META_RE.match(line)\n",
    "        if m:\n",
    "            out[m.group(\"key\").strip()] = m.group(\"val\").strip()\n",
    "    return out\n",
    "\n",
    "def get_float(d: Dict[str, str], key: str) -> Optional[float]:\n",
    "    v = d.get(key)\n",
    "    if v is None: return None\n",
    "    try:\n",
    "        return float(v)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return float(v.replace(\",\", \".\"))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def robust_image_size(p: Path) -> Tuple[int, int]:\n",
    "    with Image.open(p) as im:\n",
    "        return im.size\n",
    "\n",
    "def pair_png_and_meta(folder: Path):\n",
    "    pairs = []\n",
    "    for meta in sorted(folder.glob(\"*_metadata.txt\")):\n",
    "        stem = meta.name.replace(\"_metadata.txt\", \"\")\n",
    "        png = folder / f\"{stem}_sem.png\"\n",
    "        if not png.exists():\n",
    "            cands = sorted(folder.glob(stem + \"*.png\"))\n",
    "            png = cands[0] if cands else None\n",
    "        if png and png.exists():\n",
    "            pairs.append((png, meta, stem))\n",
    "    return pairs\n",
    "\n",
    "def build_site_records(folder: Path) -> List[SiteRecord]:\n",
    "    recs = []\n",
    "    for png, meta, stem in pair_png_and_meta(folder):\n",
    "        md = parse_metadata_txt(meta)\n",
    "\n",
    "        w = int(get_float(md, \"/1/Electron Image/Header/X Cells\") or 0)\n",
    "        h = int(get_float(md, \"/1/Electron Image/Header/Y Cells\") or 0)\n",
    "        if w == 0 or h == 0:\n",
    "            w, h = robust_image_size(png)\n",
    "\n",
    "        px_x = get_float(md, \"/1/Electron Image/Header/X Step\")\n",
    "        px_y = get_float(md, \"/1/Electron Image/Header/Y Step\")\n",
    "\n",
    "        sem_npz = png.with_suffix(\".npz\")  # e.g. \"..._sem.png\" -> \"..._sem.npz\"\n",
    "        recs.append(SiteRecord(\n",
    "            basename=stem,\n",
    "            png_path=str(png),\n",
    "            meta_path=str(meta),\n",
    "            npz_path=str(sem_npz) if sem_npz.exists() else str(sem_npz),  # keep path even if missing\n",
    "            width_px=w, height_px=h,\n",
    "            px_x_um=px_x, px_y_um=px_y,\n",
    "            tile_w_um=(w*px_x if (w and px_x) else None),\n",
    "            tile_h_um=(h*px_y if (h and px_y) else None),\n",
    "            stage_x_um=1000*get_float(md, \"/1/EDS/Header/Stage Position/X\"),\n",
    "            stage_y_um=1000*get_float(md, \"/1/EDS/Header/Stage Position/Y\"),\n",
    "            stage_z_um=1000*get_float(md, \"/1/EDS/Header/Stage Position/Z\"),\n",
    "        ))\n",
    "    return recs\n",
    "\n",
    "# simple clustering → grid row/col from stage coords\n",
    "def _cluster_1d(vals: np.ndarray, tol: float):\n",
    "    order = np.argsort(vals)\n",
    "    labels = np.empty_like(order, dtype=int)\n",
    "    centers = [vals[order[0]]] if len(order) else []\n",
    "    lab = 0\n",
    "    if len(order):\n",
    "        labels[order[0]] = 0\n",
    "        for i in order[1:]:\n",
    "            v = vals[i]\n",
    "            if abs(v - centers[-1]) > tol:\n",
    "                lab += 1; centers.append(v)\n",
    "            labels[i] = lab\n",
    "    return labels\n",
    "\n",
    "def infer_grid_indices(df_pos: pd.DataFrame, tol_frac: float = 0.55) -> Tuple[np.ndarray,np.ndarray]:\n",
    "    w_med = float(np.nanmedian(df_pos[\"tile_w_um\"])) if df_pos[\"tile_w_um\"].notna().any() else 0.0\n",
    "    h_med = float(np.nanmedian(df_pos[\"tile_h_um\"])) if df_pos[\"tile_h_um\"].notna().any() else 0.0\n",
    "    tol_x = w_med*tol_frac if w_med else max(1.0, np.ptp(df_pos[\"X_rel_um\"].to_numpy(float))/20.0)\n",
    "    tol_y = h_med*tol_frac if h_med else max(1.0, np.ptp(df_pos[\"Y_rel_um\"].to_numpy(float))/20.0)\n",
    "    cols = _cluster_1d(df_pos[\"X_rel_um\"].to_numpy(float), tol_x)\n",
    "    rows = _cluster_1d(df_pos[\"Y_rel_um\"].to_numpy(float), tol_y)\n",
    "    return rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbc8ad-b1ab-4516-ad79-1571a091b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = build_site_records(folder)\n",
    "site_df = pd.DataFrame([asdict(s) for s in sites])\n",
    "site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502cfae-992e-4dc1-8150-3f16bb8004c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add per-image low/high + dtype, then plot dtype counts once ---\n",
    "\n",
    "def _load_gray_and_dtype(path: str | Path):\n",
    "    \"\"\"\n",
    "    Load an image from disk, preserving bit depth when possible.\n",
    "    Returns (array_2d, dtype_string).\n",
    "    - If the image is multi-channel, convert to grayscale (L) for stats.\n",
    "    - Keeps 16-bit PNG/TIFF as uint16 when present.\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    with Image.open(p) as im:\n",
    "        mode = im.mode  # e.g., 'L', 'I;16', 'RGB', 'RGBA', 'I'\n",
    "        if mode in (\"I;16\",):\n",
    "            arr = np.array(im, dtype=np.uint16)\n",
    "        elif mode == \"I\":\n",
    "            arr = np.array(im, dtype=np.int32)\n",
    "        else:\n",
    "            # For any 8-bit (L/RGB/RGBA/...) convert to 8-bit grayscale\n",
    "            if mode != \"L\":\n",
    "                im = im.convert(\"L\")\n",
    "            arr = np.array(im, dtype=np.uint8)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[..., 0]\n",
    "    return arr, str(arr.dtype)\n",
    "\n",
    "# Compute per-image stats\n",
    "mins, maxs, dtypes = [], [], []\n",
    "for p in site_df[\"png_path\"]:\n",
    "    try:\n",
    "        a, dt = _load_gray_and_dtype(p)\n",
    "        a = a[np.isfinite(a)]\n",
    "        mins.append(float(a.min()) if a.size else np.nan)\n",
    "        maxs.append(float(a.max()) if a.size else np.nan)\n",
    "        dtypes.append(dt)\n",
    "    except Exception:\n",
    "        mins.append(np.nan); maxs.append(np.nan); dtypes.append(\"(unreadable)\")\n",
    "\n",
    "# Attach to df\n",
    "site_df[\"img_min\"] = mins\n",
    "site_df[\"img_max\"] = maxs\n",
    "site_df[\"img_dtype\"] = dtypes\n",
    "\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d0d18-b4dc-45f4-8804-a088516bc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pairs found: {len(site_df)}\")\n",
    "print(\"Sizes (w×h):\")\n",
    "print(site_df[[\"width_px\", \"height_px\"]].value_counts().sort_values(ascending=False).to_string())\n",
    "\n",
    "# Ensure we have absolute stage positions in µm\n",
    "need_cols = {\"stage_x_um\",\"stage_y_um\"}\n",
    "if not need_cols.issubset(site_df.columns) or site_df[list(need_cols)].isna().any().any():\n",
    "    raise ValueError(\"stage_x_um / stage_y_um required (µm).\")\n",
    "\n",
    "# --- 1) start from ABSOLUTE stage coords (µm) ---\n",
    "x_abs = site_df[\"stage_x_um\"].astype(float).to_numpy()\n",
    "y_abs = site_df[\"stage_y_um\"].astype(float).to_numpy()\n",
    "\n",
    "# --- 2) optionally invert within the dataset bounds ---\n",
    "if invertx:\n",
    "    xmin, xmax = float(np.nanmin(x_abs)), float(np.nanmax(x_abs))\n",
    "    x_abs = (xmin + xmax) - x_abs\n",
    "\n",
    "if inverty:\n",
    "    ymin, ymax = float(np.nanmin(y_abs)), float(np.nanmax(y_abs))\n",
    "    y_abs = (ymin + ymax) - y_abs\n",
    "\n",
    "# (optional) keep the inverted absolutes for reference/debug\n",
    "site_df[\"stage_x_um_inv\"] = x_abs\n",
    "site_df[\"stage_y_um_inv\"] = y_abs\n",
    "\n",
    "# --- 3) compute RELATIVE coords from the (possibly inverted) absolutes ---\n",
    "x0, y0 = float(np.nanmin(x_abs)), float(np.nanmin(y_abs))\n",
    "site_df[\"X_rel_um\"] = x_abs - x0\n",
    "site_df[\"Y_rel_um\"] = y_abs - y0\n",
    "\n",
    "site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a822b8-6dfe-4563-8f48-8b02cea1cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Global min/max + recommended clipping (from NPZ raw 'sem_data') ===\n",
    "\n",
    "# knobs\n",
    "CLIP_PERCENT    = 1.0      # e.g., 1% → use p1 / p99\n",
    "SAMPLE_PER_TILE = 5000     # how many pixels to sample per image (0 = use all)\n",
    "RNG_SEED        = 0\n",
    "\n",
    "def _load_npz_sem(path: str | Path):\n",
    "    \"\"\"Load raw SEM plane from *_sem.npz (key 'sem_data'). Returns (arr2d, dtype_str).\"\"\"\n",
    "    p = Path(path)\n",
    "    with np.load(p) as d:\n",
    "        a = d[\"sem_data\"]           # keep native dtype (often uint16)\n",
    "    if a.ndim == 3:                  # just in case\n",
    "        a = a[..., 0]\n",
    "    return a, str(a.dtype)\n",
    "\n",
    "# 0) ensure we have an npz_path column\n",
    "if \"npz_path\" not in site_df.columns:\n",
    "    raise ValueError(\"site_df is missing 'npz_path'. Add it when building records.\")\n",
    "\n",
    "# 1) per-file NPZ min/max (cached in df so we can reuse)\n",
    "if not {\"npz_min\",\"npz_max\",\"npz_dtype\"}.issubset(site_df.columns):\n",
    "    npz_mins, npz_maxs, npz_dtypes = [], [], []\n",
    "    for p in site_df[\"npz_path\"]:\n",
    "        try:\n",
    "            a, dt = _load_npz_sem(p)\n",
    "            a = a[np.isfinite(a)]\n",
    "            npz_mins.append(float(a.min()) if a.size else np.nan)\n",
    "            npz_maxs.append(float(a.max()) if a.size else np.nan)\n",
    "            npz_dtypes.append(dt)\n",
    "        except Exception:\n",
    "            npz_mins.append(np.nan); npz_maxs.append(np.nan); npz_dtypes.append(\"(missing)\")\n",
    "    site_df[\"npz_min\"]   = npz_mins\n",
    "    site_df[\"npz_max\"]   = npz_maxs\n",
    "    site_df[\"npz_dtype\"] = npz_dtypes\n",
    "\n",
    "# quick global min/max from NPZs\n",
    "GLOBAL_MIN = float(np.nanmin(site_df[\"npz_min\"].to_numpy()))\n",
    "GLOBAL_MAX = float(np.nanmax(site_df[\"npz_max\"].to_numpy()))\n",
    "print(f\"Global raw min/max from NPZ: {GLOBAL_MIN:.3g}, {GLOBAL_MAX:.3g}\")\n",
    "\n",
    "# 2) robust global lo/hi by sampling pixels from NPZs\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "samples = []\n",
    "for p in site_df[\"npz_path\"]:\n",
    "    try:\n",
    "        a, _ = _load_npz_sem(p)\n",
    "        flat = a.ravel().astype(np.float64, copy=False)\n",
    "        if SAMPLE_PER_TILE and flat.size > SAMPLE_PER_TILE:\n",
    "            idx = rng.choice(flat.size, SAMPLE_PER_TILE, replace=False)\n",
    "            flat = flat[idx]\n",
    "        samples.append(flat)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if samples:\n",
    "    all_samples = np.concatenate(samples)\n",
    "    if CLIP_PERCENT and CLIP_PERCENT > 0:\n",
    "        GLOBAL_LO, GLOBAL_HI = np.nanpercentile(all_samples, [CLIP_PERCENT, 100.0 - CLIP_PERCENT])\n",
    "    else:\n",
    "        GLOBAL_LO, GLOBAL_HI = float(np.nanmin(all_samples)), float(np.nanmax(all_samples))\n",
    "else:\n",
    "    # fallback to raw extremes if sampling failed\n",
    "    GLOBAL_LO, GLOBAL_HI = GLOBAL_MIN, GLOBAL_MAX\n",
    "\n",
    "print(f\"Recommended NPZ clipping @ {CLIP_PERCENT}%: lo={GLOBAL_LO:.3g}, hi={GLOBAL_HI:.3g}\")\n",
    "\n",
    "# 3) stash constants in the dataframe for downstream plotting/normalization\n",
    "site_df[\"global_min\"]   = GLOBAL_MIN\n",
    "site_df[\"global_max\"]   = GLOBAL_MAX\n",
    "site_df[\"global_lo\"]    = float(GLOBAL_LO)\n",
    "site_df[\"global_hi\"]    = float(GLOBAL_HI)\n",
    "site_df[\"clip_percent\"] = CLIP_PERCENT\n",
    "\n",
    "site_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0d7fa-613c-4899-a66f-fc02273c29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Min/Max of X_rel_um, Y_rel_um + quick plot ===\n",
    "\n",
    "df_mm = site_df.copy()\n",
    "\n",
    "# If relative coords missing, derive from stage coords\n",
    "if (\"X_rel_um\" not in df_mm.columns) or df_mm[\"X_rel_um\"].isna().any():\n",
    "    if {\"stage_x_um\",\"stage_y_um\"}.issubset(df_mm.columns) and df_mm[[\"stage_x_um\",\"stage_y_um\"]].notna().all(axis=None):\n",
    "        x0, y0 = float(df_mm[\"stage_x_um\"].min()), float(df_mm[\"stage_y_um\"].min())\n",
    "        df_mm[\"X_rel_um\"] = df_mm[\"stage_x_um\"] - x0\n",
    "        df_mm[\"Y_rel_um\"] = df_mm[\"stage_y_um\"] - y0\n",
    "    else:\n",
    "        raise ValueError(\"No X_rel_um/Y_rel_um or stage_x_um/stage_y_um available.\")\n",
    "\n",
    "# Drop NAs and compute mins/maxes\n",
    "x = df_mm[\"X_rel_um\"].astype(float).dropna()\n",
    "y = df_mm[\"Y_rel_um\"].astype(float).dropna()\n",
    "xmin, xmax = float(x.min()), float(x.max())\n",
    "ymin, ymax = float(y.min()), float(y.max())\n",
    "\n",
    "print(f\"X_rel_um: min={xmin:.6f} µm, max={xmax:.6f} µm, span={xmax-xmin:.6f} µm\")\n",
    "print(f\"Y_rel_um: min={ymin:.6f} µm, max={ymax:.6f} µm, span={ymax-ymin:.6f} µm\")\n",
    "\n",
    "# Four corners for visualization\n",
    "corners = {\n",
    "    \"NW\": (xmin, ymin),\n",
    "    \"NE\": (xmax, ymin),\n",
    "    \"SW\": (xmin, ymax),\n",
    "    \"SE\": (xmax, ymax),\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Invisible trace to auto-set bounds\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[xmin, xmax], y=[ymin, ymax],\n",
    "    mode=\"markers\", opacity=0, showlegend=False, hoverinfo=\"skip\"\n",
    "))\n",
    "\n",
    "# Rectangle showing the span box\n",
    "fig.add_shape(\n",
    "    type=\"rect\", x0=xmin, y0=ymin, x1=xmax, y1=ymax,\n",
    "    line=dict(width=3), fillcolor=None\n",
    ")\n",
    "\n",
    "# Corner markers with labels\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[v[0] for v in corners.values()],\n",
    "    y=[v[1] for v in corners.values()],\n",
    "    mode=\"markers+text\",\n",
    "    text=list(corners.keys()),\n",
    "    textposition=\"top center\",\n",
    "    name=\"Corners\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Extent of relative coordinates\",\n",
    "    xaxis_title=\"X_rel_um (µm)\",\n",
    "    yaxis_title=\"Y_rel_um (µm, top-down)\",\n",
    "    height=500, margin=dict(l=60, r=20, t=50, b=60),\n",
    "    plot_bgcolor=\"white\"\n",
    ")\n",
    "fig.update_xaxes(showline=True, mirror=True, zeroline=False, ticks=\"outside\")\n",
    "fig.update_yaxes(showline=True, mirror=True, zeroline=False, ticks=\"outside\",\n",
    "                 scaleanchor=\"x\", autorange=\"reversed\")  # top-left origin\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392128a-c004-4efb-9f68-afa7a8e82530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plot all positions (X_rel_um, Y_rel_um) with bounding rectangle ===\n",
    "\n",
    "D = site_df.copy()\n",
    "\n",
    "# Ensure relative coords exist\n",
    "if (\"X_rel_um\" not in D.columns) or D[\"X_rel_um\"].isna().any():\n",
    "    if {\"stage_x_um\",\"stage_y_um\"}.issubset(D.columns) and D[[\"stage_x_um\",\"stage_y_um\"]].notna().all(axis=None):\n",
    "        x0, y0 = float(D[\"stage_x_um\"].min()), float(D[\"stage_y_um\"].min())\n",
    "        D[\"X_rel_um\"] = D[\"stage_x_um\"] - x0\n",
    "        D[\"Y_rel_um\"] = D[\"stage_y_um\"] - y0\n",
    "    else:\n",
    "        raise ValueError(\"Need X_rel_um/Y_rel_um or stage_x_um/stage_y_um.\")\n",
    "\n",
    "# keep rows with finite coords\n",
    "D = D[np.isfinite(D[\"X_rel_um\"]) & np.isfinite(D[\"Y_rel_um\"])].copy()\n",
    "\n",
    "# bounds\n",
    "xmin, xmax = float(D[\"X_rel_um\"].min()), float(D[\"X_rel_um\"].max())\n",
    "ymin, ymax = float(D[\"Y_rel_um\"].min()), float(D[\"Y_rel_um\"].max())\n",
    "\n",
    "# hover labels\n",
    "name_col = \"Label\" if \"Label\" in D.columns else (\"basename\" if \"basename\" in D.columns else None)\n",
    "hover_text = (D[name_col].astype(str) if name_col else D.index.astype(str))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# bounding rectangle\n",
    "fig.add_shape(type=\"rect\", x0=xmin, y0=ymin, x1=xmax, y1=ymax,\n",
    "              line=dict(width=2), fillcolor=None)\n",
    "\n",
    "# all points\n",
    "fig.add_trace(go.Scattergl(\n",
    "    x=D[\"X_rel_um\"],\n",
    "    y=D[\"Y_rel_um\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5, opacity=0.7),\n",
    "    text=hover_text,\n",
    "    hovertemplate=\"idx=%{customdata}<br>X=%{x:.3f} µm<br>Y=%{y:.3f} µm<br>%{text}\",\n",
    "    customdata=D.index,\n",
    "    name=\"positions\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"All positions in relative-coordinate space\",\n",
    "    xaxis_title=\"X_rel_um (µm)\",\n",
    "    yaxis_title=\"Y_rel_um (µm, top-down)\",\n",
    "    height=650, margin=dict(l=60, r=20, t=50, b=60),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "# 1:1 aspect and top-left origin\n",
    "fig.update_xaxes(showline=True, mirror=True, zeroline=False, ticks=\"outside\")\n",
    "fig.update_yaxes(showline=True, mirror=True, zeroline=False, ticks=\"outside\",\n",
    "                 scaleanchor=\"x\", autorange=\"reversed\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9a0f9-b4f2-4bc5-b8db-05b7a911c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plot rectangles for every position ===\n",
    "\n",
    "# 1) Build/refresh the dataframe if you haven't already in this session\n",
    "# records = build_site_records(Path(r\"/media/lenr/Data/semeds/20250401 #12 (eds)/Project 1/pythondata\"))\n",
    "# site_df = pd.DataFrame([asdict(r) for r in records])\n",
    "\n",
    "D = site_df.copy()\n",
    "\n",
    "# 2) Ensure tile sizes in µm exist (px * µm/px as fallback)\n",
    "if (\"TileWidth_um\" not in D.columns) or D[\"TileWidth_um\"].isna().any():\n",
    "    if {\"width_px\",\"px_x_um\"}.issubset(D.columns):\n",
    "        D[\"TileWidth_um\"] = D.get(\"TileWidth_um\")\n",
    "        m = D[\"TileWidth_um\"].isna()\n",
    "        D.loc[m, \"TileWidth_um\"] = D.loc[m, \"width_px\"] * D.loc[m, \"px_x_um\"]\n",
    "if (\"TileHeight_um\" not in D.columns) or D[\"TileHeight_um\"].isna().any():\n",
    "    if {\"height_px\",\"px_y_um\"}.issubset(D.columns):\n",
    "        D[\"TileHeight_um\"] = D.get(\"TileHeight_um\")\n",
    "        m = D[\"TileHeight_um\"].isna()\n",
    "        D.loc[m, \"TileHeight_um\"] = D.loc[m, \"height_px\"] * D.loc[m, \"px_y_um\"]\n",
    "\n",
    "# 3) Ensure relative stage coords in µm exist\n",
    "if (\"X_rel_um\" not in D.columns) or D[\"X_rel_um\"].isna().any() or (\"Y_rel_um\" not in D.columns):\n",
    "    x0, y0 = float(D[\"stage_x_um\"].min()), float(D[\"stage_y_um\"].min())\n",
    "    D[\"X_rel_um\"] = D[\"stage_x_um\"] - x0\n",
    "    D[\"Y_rel_um\"] = D[\"stage_y_um\"] - y0\n",
    "\n",
    "# 4) Keep only rows with complete geometry\n",
    "need = [\"X_rel_um\",\"Y_rel_um\",\"TileWidth_um\",\"TileHeight_um\"]\n",
    "D = D.dropna(subset=need).copy()\n",
    "\n",
    "# 5) Vectorized rectangle geometry\n",
    "x0 = D[\"X_rel_um\"].to_numpy(float)\n",
    "y0 = D[\"Y_rel_um\"].to_numpy(float)\n",
    "x1 = (D[\"X_rel_um\"] + D[\"TileWidth_um\"]).to_numpy(float)\n",
    "y1 = (D[\"Y_rel_um\"] + D[\"TileHeight_um\"]).to_numpy(float)\n",
    "\n",
    "# 6) Build plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# invisible trace → sets bounds quickly\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[x0.min(), x1.max()],\n",
    "    y=[y0.min(), y1.max()],\n",
    "    mode=\"markers\", opacity=0, showlegend=False, hoverinfo=\"skip\"\n",
    "))\n",
    "\n",
    "# all rectangles as layout shapes (fast for a few thousand)\n",
    "fig.update_layout(\n",
    "    shapes=[dict(type=\"rect\", x0=a, y0=b, x1=c, y1=d, line=dict(width=1))\n",
    "            for a, b, c, d in zip(x0, y0, x1, y1)],\n",
    "    title=\"All tiles (top-left origin)\",\n",
    "    height=800, margin=dict(l=60, r=20, t=50, b=60),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "# 1:1 aspect, top-down Y\n",
    "fig.update_xaxes(title=\"X (µm)\", showline=True, mirror=True, zeroline=False, ticks=\"outside\")\n",
    "fig.update_yaxes(title=\"Y (µm, top-down)\", showline=True, mirror=True, zeroline=False,\n",
    "                 ticks=\"outside\", scaleanchor=\"x\", autorange=\"reversed\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f2b1-8190-4faa-9f12-87dbcf93a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overlay first/last N thumbnails on the grid ===\n",
    "\n",
    "D = site_df.copy()\n",
    "\n",
    "# knobs\n",
    "N_FIRST = 500\n",
    "N_LAST  = 500\n",
    "THUMB_MAX_SIDE = 400     # px (downscale if either side larger)\n",
    "IMG_OPACITY = 1.0        # 0..1\n",
    "\n",
    "# --- ensure geometry (same logic as before) ---\n",
    "if (\"TileWidth_um\" not in D.columns) or D[\"TileWidth_um\"].isna().any():\n",
    "    if {\"width_px\",\"px_x_um\"}.issubset(D.columns):\n",
    "        D[\"TileWidth_um\"] = D.get(\"TileWidth_um\")\n",
    "        m = D[\"TileWidth_um\"].isna()\n",
    "        D.loc[m, \"TileWidth_um\"] = D.loc[m, \"width_px\"] * D.loc[m, \"px_x_um\"]\n",
    "if (\"TileHeight_um\" not in D.columns) or D[\"TileHeight_um\"].isna().any():\n",
    "    if {\"height_px\",\"px_y_um\"}.issubset(D.columns):\n",
    "        D[\"TileHeight_um\"] = D.get(\"TileHeight_um\")\n",
    "        m = D[\"TileHeight_um\"].isna()\n",
    "        D.loc[m, \"TileHeight_um\"] = D.loc[m, \"height_px\"] * D.loc[m, \"px_y_um\"]\n",
    "\n",
    "if (\"X_rel_um\" not in D.columns) or (\"Y_rel_um\" not in D.columns) or D[\"X_rel_um\"].isna().any() or D[\"Y_rel_um\"].isna().any():\n",
    "    x0, y0 = float(D[\"stage_x_um\"].min()), float(D[\"stage_y_um\"].min())\n",
    "    D[\"X_rel_um\"] = D[\"stage_x_um\"] - x0\n",
    "    D[\"Y_rel_um\"] = D[\"stage_y_um\"] - y0\n",
    "\n",
    "# rows we can actually place + have an image path\n",
    "geom_cols = [\"X_rel_um\",\"Y_rel_um\",\"TileWidth_um\",\"TileHeight_um\",\"png_path\"]\n",
    "Dv = D.dropna(subset=geom_cols).copy()\n",
    "\n",
    "# choose first/last without duplicating the middle if dataset < N_FIRST+N_LAST\n",
    "sel = pd.concat([Dv.head(N_FIRST), Dv.tail(N_LAST)])\n",
    "sel = sel.loc[~sel.index.duplicated(keep=\"first\")].copy()\n",
    "\n",
    "# --- helper: load + downscale to uint8 RGB ---\n",
    "def load_png_uint8(path, max_side=900):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    if max(w, h) > max_side:\n",
    "        s = max_side / float(max(w, h))\n",
    "        im = im.resize((max(1, int(round(w*s))), max(1, int(round(h*s)))), Image.BILINEAR)\n",
    "    arr = np.asarray(im, dtype=np.uint8)\n",
    "    im.close()\n",
    "    return Image.fromarray(arr, mode=\"RGB\")\n",
    "\n",
    "# --- base figure with all rectangles (as before) ---\n",
    "x0 = Dv[\"X_rel_um\"].to_numpy(float)\n",
    "y0 = Dv[\"Y_rel_um\"].to_numpy(float)\n",
    "x1 = (Dv[\"X_rel_um\"] + Dv[\"TileWidth_um\"]).to_numpy(float)\n",
    "y1 = (Dv[\"Y_rel_um\"] + Dv[\"TileHeight_um\"]).to_numpy(float)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[x0.min(), x1.max()], y=[y0.min(), y1.max()],\n",
    "                         mode=\"markers\", opacity=0, showlegend=False, hoverinfo=\"skip\"))\n",
    "fig.update_layout(\n",
    "    shapes=[dict(type=\"rect\", x0=a, y0=b, x1=c, y1=d, line=dict(width=1))\n",
    "            for a, b, c, d in zip(x0, y0, x1, y1)],\n",
    "    title=f\"Tiles with {len(sel)} thumbnails (top-left origin)\",\n",
    "    height=800, margin=dict(l=60, r=20, t=50, b=60),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "fig.update_xaxes(title=\"X (µm)\", showline=True, mirror=True, zeroline=False, ticks=\"outside\")\n",
    "fig.update_yaxes(title=\"Y (µm, top-down)\", showline=True, mirror=True, zeroline=False,\n",
    "                 ticks=\"outside\", scaleanchor=\"x\", autorange=\"reversed\")\n",
    "\n",
    "# --- overlay thumbnails below the grid lines ---\n",
    "missed = 0\n",
    "for _, r in sel.iterrows():\n",
    "    try:\n",
    "        img = load_png_uint8(r[\"png_path\"], max_side=THUMB_MAX_SIDE)\n",
    "        fig.add_layout_image(dict(\n",
    "            source=img,\n",
    "            x=float(r[\"X_rel_um\"]),\n",
    "            y=float(r[\"Y_rel_um\"]),\n",
    "            xref=\"x\", yref=\"y\",\n",
    "            sizex=float(r[\"TileWidth_um\"]),\n",
    "            sizey=float(r[\"TileHeight_um\"]),\n",
    "            xanchor=\"left\", yanchor=\"top\",\n",
    "            sizing=\"stretch\",\n",
    "            layer=\"below\",\n",
    "            opacity=IMG_OPACITY,\n",
    "        ))\n",
    "    except Exception:\n",
    "        missed += 1\n",
    "if missed:\n",
    "    print(f\"Skipped {missed} images that could not be read.\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b215c-640e-4e94-92a7-6852b7fcf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overlay thumbnails from NPZ 'sem_data' with uniform NPZ-based clipping ===\n",
    "\n",
    "D = site_df.copy()\n",
    "\n",
    "# knobs\n",
    "N_FIRST = 500\n",
    "N_LAST  = 500\n",
    "THUMB_MAX_SIDE = 400  # px (downscale if either side larger)\n",
    "IMG_OPACITY = 1.0     # 0..1\n",
    "USE_GLOBAL = True     # True: use NPZ global_lo/global_hi; False: per-image NPZ min/max\n",
    "\n",
    "# --- geometry prep (unchanged) ---\n",
    "if (\"TileWidth_um\" not in D.columns) or D[\"TileWidth_um\"].isna().any():\n",
    "    if {\"width_px\",\"px_x_um\"}.issubset(D.columns):\n",
    "        D[\"TileWidth_um\"] = D.get(\"TileWidth_um\")\n",
    "        m = D[\"TileWidth_um\"].isna()\n",
    "        D.loc[m, \"TileWidth_um\"] = D.loc[m, \"width_px\"] * D.loc[m, \"px_x_um\"]\n",
    "if (\"TileHeight_um\" not in D.columns) or D[\"TileHeight_um\"].isna().any():\n",
    "    if {\"height_px\",\"px_y_um\"}.issubset(D.columns):\n",
    "        D[\"TileHeight_um\"] = D.get(\"TileHeight_um\")\n",
    "        m = D[\"TileHeight_um\"].isna()\n",
    "        D.loc[m, \"TileHeight_um\"] = D.loc[m, \"height_px\"] * D.loc[m, \"px_y_um\"]\n",
    "\n",
    "if (\"X_rel_um\" not in D.columns) or (\"Y_rel_um\" not in D.columns) or D[\"X_rel_um\"].isna().any() or D[\"Y_rel_um\"].isna().any():\n",
    "    x0, y0 = float(D[\"stage_x_um\"].min()), float(D[\"stage_y_um\"].min())\n",
    "    D[\"X_rel_um\"] = D[\"stage_x_um\"] - x0\n",
    "    D[\"Y_rel_um\"] = D[\"stage_y_um\"] - y0\n",
    "\n",
    "# rows we can actually place + have NPZ path\n",
    "geom_cols = [\"X_rel_um\",\"Y_rel_um\",\"TileWidth_um\",\"TileHeight_um\",\"npz_path\"]\n",
    "Dv = D.dropna(subset=geom_cols).copy()\n",
    "\n",
    "# choose first/last without duplicating the middle if dataset < N_FIRST+N_LAST\n",
    "sel = pd.concat([Dv.head(N_FIRST), Dv.tail(N_LAST)])\n",
    "sel = sel.loc[~sel.index.duplicated(keep=\"first\")].copy()\n",
    "\n",
    "# NPZ global lo/hi\n",
    "if USE_GLOBAL:\n",
    "    assert {\"global_lo\",\"global_hi\"}.issubset(D.columns), \"Need global_lo/global_hi in site_df\"\n",
    "    lo_global = float(D[\"global_lo\"].iloc[0])\n",
    "    hi_global = float(D[\"global_hi\"].iloc[0])\n",
    "\n",
    "# --- helpers (NPZ first, PNG fallback for rare missing files) -----------------\n",
    "def load_npz_gray(path: str | Path) -> np.ndarray:\n",
    "    \"\"\"Return raw 2D array from *_sem.npz (key 'sem_data').\"\"\"\n",
    "    with np.load(path) as z:\n",
    "        a = z[\"sem_data\"]\n",
    "    if a.ndim == 3:\n",
    "        a = a[..., 0]\n",
    "    return a\n",
    "\n",
    "def load_png_gray(path: str | Path) -> np.ndarray:\n",
    "    from PIL import Image\n",
    "    with Image.open(path) as im:\n",
    "        if im.mode != \"L\":\n",
    "            im = im.convert(\"L\")\n",
    "        return np.asarray(im)\n",
    "\n",
    "def load_raw_gray(row) -> np.ndarray:\n",
    "    p_npz = Path(row[\"npz_path\"])\n",
    "    if p_npz.exists():\n",
    "        try:\n",
    "            return load_npz_gray(p_npz)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # PNG fallback (already tone-mapped, but better than nothing)\n",
    "    return load_png_gray(Path(row[\"png_path\"]))\n",
    "\n",
    "def normalize_to_uint8(arr, lo, hi):\n",
    "    \"\"\"Clip to [lo,hi] then rescale to 0..255 uint8.\"\"\"\n",
    "    a = arr.astype(np.float32, copy=False)\n",
    "    a = np.clip(a, lo, hi)\n",
    "    if hi <= lo:\n",
    "        return np.zeros_like(a, dtype=np.uint8)\n",
    "    a = (a - lo) * (255.0 / (hi - lo))\n",
    "    return a.astype(np.uint8, copy=False)\n",
    "\n",
    "def norm_thumb_from_row(row, max_side=400):\n",
    "    \"\"\"Load NPZ raw, normalize (global or per-image), downscale, return PIL RGB.\"\"\"\n",
    "    arr = load_raw_gray(row)\n",
    "    if USE_GLOBAL:\n",
    "        lo, hi = lo_global, hi_global\n",
    "    else:\n",
    "        # per-image NPZ min/max (use cached columns if present; else compute)\n",
    "        lo = float(row.get(\"npz_min\", np.nan))\n",
    "        hi = float(row.get(\"npz_max\", np.nan))\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
    "            lo, hi = float(np.min(arr)), float(np.max(arr))\n",
    "    arr8 = normalize_to_uint8(arr, lo, hi)\n",
    "    im = Image.fromarray(arr8, mode=\"L\")\n",
    "    w, h = im.size\n",
    "    if max(w, h) > max_side:\n",
    "        s = max_side / float(max(w, h))\n",
    "        im = im.resize((max(1, int(round(w*s))), max(1, int(round(h*s)))), Image.BILINEAR)\n",
    "    return im.convert(\"RGB\")\n",
    "\n",
    "# --- base figure with all rectangles -----------------------------------------\n",
    "x0 = Dv[\"X_rel_um\"].to_numpy(float)\n",
    "y0 = Dv[\"Y_rel_um\"].to_numpy(float)\n",
    "x1 = (Dv[\"X_rel_um\"] + Dv[\"TileWidth_um\"]).to_numpy(float)\n",
    "y1 = (Dv[\"Y_rel_um\"] + Dv[\"TileHeight_um\"]).to_numpy(float)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[x0.min(), x1.max()], y=[y0.min(), y1.max()],\n",
    "                         mode=\"markers\", opacity=0, showlegend=False, hoverinfo=\"skip\"))\n",
    "fig.update_layout(\n",
    "    shapes=[dict(type=\"rect\", x0=a, y0=b, x1=c, y1=d, line=dict(width=1))\n",
    "            for a, b, c, d in zip(x0, y0, x1, y1)],\n",
    "    title=f\"Tiles with {len(sel)} NPZ-normalized thumbnails (top-left origin)\"\n",
    "          + (\" — global clip\" if USE_GLOBAL else \" — per-image NPZ clip\"),\n",
    "    height=800, margin=dict(l=60, r=20, t=50, b=60),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "fig.update_xaxes(title=\"X (µm)\", showline=False, mirror=True, zeroline=False, ticks=\"outside\")\n",
    "fig.update_yaxes(title=\"Y (µm, top-down)\", showline=False, mirror=True, zeroline=False,\n",
    "                 ticks=\"outside\", scaleanchor=\"x\", autorange=\"reversed\")\n",
    "\n",
    "fig.update_xaxes(showgrid=False, zeroline=False)\n",
    "fig.update_yaxes(showgrid=False, zeroline=False)\n",
    "\n",
    "# --- overlay thumbnails below the grid lines ---------------------------------\n",
    "missed = 0\n",
    "for _, r in sel.iterrows():\n",
    "    try:\n",
    "        img = norm_thumb_from_row(r, max_side=THUMB_MAX_SIDE)\n",
    "        fig.add_layout_image(dict(\n",
    "            source=img,\n",
    "            x=float(r[\"X_rel_um\"]),\n",
    "            y=float(r[\"Y_rel_um\"]),\n",
    "            xref=\"x\", yref=\"y\",\n",
    "            sizex=float(r[\"TileWidth_um\"]),\n",
    "            sizey=float(r[\"TileHeight_um\"]),\n",
    "            xanchor=\"left\", yanchor=\"top\",\n",
    "            sizing=\"stretch\",\n",
    "            layer=\"below\",\n",
    "            opacity=IMG_OPACITY,\n",
    "        ))\n",
    "    except Exception:\n",
    "        missed += 1\n",
    "\n",
    "if missed:\n",
    "    print(f\"Skipped {missed} thumbnails (missing/bad NPZ or PNG).\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531e6f8-195e-4a60-be92-dcac57d8e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Write summary_table.csv for stitch_h5data.py ===\n",
    "\n",
    "D = site_df.copy()\n",
    "\n",
    "# 1) Ensure required columns exist / are derivable\n",
    "need_xy = {\"X_rel_um\", \"Y_rel_um\"}\n",
    "if not need_xy.issubset(D.columns):\n",
    "    raise ValueError(f\"Missing columns: {sorted(need_xy - set(D.columns))}\")\n",
    "\n",
    "# npz_path: if missing, derive from png_path (same stem, .npz)\n",
    "if \"npz_path\" not in D.columns:\n",
    "    if \"png_path\" not in D.columns:\n",
    "        raise ValueError(\"Need 'npz_path' or 'png_path' to derive it.\")\n",
    "    D[\"npz_path\"] = D[\"png_path\"].map(lambda p: str(Path(p).with_suffix(\".npz\")))\n",
    "\n",
    "# Z_layer: optional; default to 0\n",
    "if \"Z_layer\" not in D.columns:\n",
    "    D[\"Z_layer\"] = 0\n",
    "\n",
    "# 2) Make sure tile sizes are available in either form:\n",
    "#    A) TileWidth_um/TileHeight_um (+ px_x_um/px_y_um)  OR  B) width_px/height_px\n",
    "has_um  = {\"TileWidth_um\", \"TileHeight_um\"}.issubset(D.columns)\n",
    "has_px  = {\"width_px\", \"height_px\"}.issubset(D.columns)\n",
    "\n",
    "# If we lack µm sizes but have pixels + pixel size, compute them\n",
    "if not has_um and has_px and {\"px_x_um\",\"px_y_um\"}.issubset(D.columns):\n",
    "    D[\"TileWidth_um\"]  = D[\"width_px\"]  * D[\"px_x_um\"]\n",
    "    D[\"TileHeight_um\"] = D[\"height_px\"] * D[\"px_y_um\"]\n",
    "    has_um = True\n",
    "\n",
    "# If we lack pixel sizes but have µm sizes + px size, compute pixels (helps sanity checks downstream)\n",
    "if not has_px and has_um and {\"px_x_um\",\"px_y_um\"}.issubset(D.columns):\n",
    "    D[\"width_px\"]  = (D[\"TileWidth_um\"]  / D[\"px_x_um\"]).round().astype(\"Int64\")\n",
    "    D[\"height_px\"] = (D[\"TileHeight_um\"] / D[\"px_y_um\"]).round().astype(\"Int64\")\n",
    "    has_px = True\n",
    "\n",
    "# Final guard: we need at least ONE size representation resolvable\n",
    "if not (has_um or has_px):\n",
    "    raise ValueError(\n",
    "        \"summary_table.csv needs either (TileWidth_um & TileHeight_um [+ px_x_um/px_y_um]) \"\n",
    "        \"or (width_px & height_px). Please add those to site_df.\"\n",
    "    )\n",
    "\n",
    "# 3) Type hygiene (helps downstream)\n",
    "for c in [\"X_rel_um\",\"Y_rel_um\",\"TileWidth_um\",\"TileHeight_um\",\"px_x_um\",\"px_y_um\"]:\n",
    "    if c in D.columns:\n",
    "        D[c] = pd.to_numeric(D[c], errors=\"coerce\")\n",
    "for c in [\"width_px\",\"height_px\",\"Z_layer\"]:\n",
    "    if c in D.columns:\n",
    "        D[c] = pd.to_numeric(D[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 4) Choose an output folder: use the parent of the first NPZ (fallback: CWD)\n",
    "try:\n",
    "    out_dir = Path(D[\"npz_path\"].dropna().iloc[0]).parent\n",
    "except Exception:\n",
    "    out_dir = Path.cwd()\n",
    "out_path = out_dir / \"summary_table.csv\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5) Column order: put stitcher-important columns first, then all others\n",
    "first_cols = [\n",
    "    \"X_rel_um\", \"Y_rel_um\", \"Z_layer\", \"npz_path\",\n",
    "    # either/both of these groups may exist; include whichever you have:\n",
    "    \"TileWidth_um\", \"TileHeight_um\", \"px_x_um\", \"px_y_um\",\n",
    "    \"width_px\", \"height_px\",\n",
    "]\n",
    "ordered = [c for c in first_cols if c in D.columns] + [c for c in D.columns if c not in first_cols]\n",
    "D = D[ordered]\n",
    "\n",
    "# 6) Write CSV (utf-8, no index)\n",
    "D.to_csv(out_path, index=False)\n",
    "print(f\"✅ Wrote {out_path}  ({len(D)} rows, {D.shape[1]} columns)\")\n",
    "print(\"First columns:\", ordered[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe69b1-08b0-44b4-825e-30aae7cc9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Write config.txt with a single px_x_um if possible ---\n",
    "\n",
    "# We expect pixel sizes to be uniform across all tiles.\n",
    "px_x_vals = []\n",
    "px_y_vals = []\n",
    "\n",
    "if \"px_x_um\" in D.columns:\n",
    "    px_x_vals = D[\"px_x_um\"].dropna().unique()\n",
    "if \"px_y_um\" in D.columns:\n",
    "    px_y_vals = D[\"px_y_um\"].dropna().unique()\n",
    "\n",
    "px_x_um = float(px_x_vals[0]) if len(px_x_vals) == 1 else None\n",
    "px_y_um = float(px_y_vals[0]) if len(px_y_vals) == 1 else None\n",
    "\n",
    "if px_x_um is not None and px_y_um is not None and np.isclose(px_x_um, px_y_um):\n",
    "    config_value = px_x_um\n",
    "\n",
    "    config_path = out_dir / \"config.txt\"\n",
    "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"um_per_px={config_value}\\n\")\n",
    "\n",
    "    print(f\"Wrote config.txt with px_x_um={config_value}\")\n",
    "else:\n",
    "    print(\"px_x_um and px_y_um differ or are missing; not writing config.txt\")\n",
    "    print(\"Unique px_x_um:\", px_x_vals)\n",
    "    print(\"Unique px_y_um:\", px_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58144a5c-2ea5-4450-8f57-1e903206afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of brightness values across ALL tiles (NPZ) — final cell\n",
    "# Assumes `site_df` exists and has an `npz_path` column pointing to .npz files\n",
    "# The code streams arrays tile-by-tile to avoid loading everything into memory.\n",
    "\n",
    "# --- knobs ---\n",
    "NUM_BINS = 1024       # histogram bins (increase for finer granularity)\n",
    "LOG_Y    = True       # plot counts on log scale for visibility\n",
    "\n",
    "# --- discover NPZ files from the dataframe ---\n",
    "paths = []\n",
    "if \"npz_path\" in site_df.columns:\n",
    "    for p in site_df[\"npz_path\"].dropna().tolist():\n",
    "        if isinstance(p, str) and os.path.isfile(p):\n",
    "            paths.append(p)\n",
    "\n",
    "if not paths:\n",
    "    raise SystemExit(\"No NPZ files found in site_df['npz_path'].\")\n",
    "\n",
    "# --- pass 1: find global min/max and total pixels ---\n",
    "gmin, gmax, total_px = None, None, 0\n",
    "for npz in paths:\n",
    "    try:\n",
    "        d = np.load(npz)\n",
    "        arr = d[\"sem_data\"] if \"sem_data\" in d.files else d[d.files[0]]\n",
    "        if arr.ndim == 3 and arr.shape[-1] == 1:\n",
    "            arr = arr[..., 0]\n",
    "        amin = int(arr.min())\n",
    "        amax = int(arr.max())\n",
    "        gmin = amin if gmin is None else min(gmin, amin)\n",
    "        gmax = amax if gmax is None else max(gmax, amax)\n",
    "        total_px += arr.size\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] could not read {npz}: {e}\")\n",
    "\n",
    "if gmin is None or gmax is None:\n",
    "    raise SystemExit(\"Could not compute global range from NPZ files.\")\n",
    "\n",
    "# Choose bin edges across observed data range\n",
    "bin_edges = np.linspace(gmin, gmax, NUM_BINS + 1, dtype=np.float64)\n",
    "\n",
    "# --- pass 2: accumulate histogram ---\n",
    "hist = np.zeros(NUM_BINS, dtype=np.int64)\n",
    "for npz in paths:\n",
    "    try:\n",
    "        d = np.load(npz)\n",
    "        arr = d[\"sem_data\"] if \"sem_data\" in d.files else d[d.files[0]]\n",
    "        if arr.ndim == 3 and arr.shape[-1] == 1:\n",
    "            arr = arr[..., 0]\n",
    "        h, _ = np.histogram(arr.ravel(), bins=bin_edges)\n",
    "        hist += h\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- derive a few useful stats from the histogram ---\n",
    "cdf = np.cumsum(hist).astype(np.float64)\n",
    "cdf /= (cdf[-1] if cdf[-1] else 1.0)\n",
    "\n",
    "def percentile_from_hist(cdf, edges, p):\n",
    "    idx = np.searchsorted(cdf, p/100.0, side=\"left\")\n",
    "    idx = np.clip(idx, 0, len(edges)-2)\n",
    "    return edges[idx]\n",
    "\n",
    "p1  = float(percentile_from_hist(cdf, bin_edges, 1.0))\n",
    "p50 = float(percentile_from_hist(cdf, bin_edges, 50.0))\n",
    "p99 = float(percentile_from_hist(cdf, bin_edges, 99.0))\n",
    "\n",
    "print(f\"Global NPZ range: min={gmin}, max={gmax}   (pixels: {total_px:,})\")\n",
    "print(f\"Approx percentiles from histogram: p1≈{int(round(p1))}, p50≈{int(round(p50))}, p99≈{int(round(p99))}\")\n",
    "\n",
    "# --- plot ---\n",
    "# --- plot with low/high clipping guides at 1%, 2%, 5% ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute low/high cutoff values from the histogram CDF\n",
    "# choose clip percents\n",
    "clips = [0.5, 1.0, 5.0]  # percent\n",
    "\n",
    "# compute low/high cutoff values from the histogram CDF\n",
    "clip_vals = []\n",
    "for p in clips:\n",
    "    lo_p = percentile_from_hist(cdf, bin_edges, p)\n",
    "    hi_p = percentile_from_hist(cdf, bin_edges, 100.0 - p)\n",
    "    clip_vals.append((p, float(lo_p), float(hi_p)))\n",
    "\n",
    "# base plot\n",
    "centers = (bin_edges[:-1] + bin_edges[1:]) * 0.5\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(centers, hist, drawstyle=\"steps-mid\", label=\"Histogram\")\n",
    "if LOG_Y:\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "# colors aligned with clips (avoid float dict lookups)\n",
    "clip_colors = dict(zip(clips, [\"#d62728\", \"#ff7f0e\", \"#2ca02c\"]))  # red, orange, green\n",
    "fmt_pct = lambda x: f\"{x:g}\"  # 0.5 -> \"0.5\", 1.0 -> \"1\", 5.0 -> \"5\"\n",
    "\n",
    "# draw lines + light shading\n",
    "for p, lo_v, hi_v in clip_vals:\n",
    "    c = clip_colors[p]\n",
    "    plt.axvline(lo_v, color=c, linestyle=\"--\", linewidth=1.5, label=f\"{fmt_pct(p)}% lo\")\n",
    "    plt.axvline(hi_v, color=c, linestyle=\"--\", linewidth=1.5, label=f\"{fmt_pct(p)}% hi\")\n",
    "    y0, y1 = plt.ylim()\n",
    "    plt.fill_betweenx([y0, y1], bin_edges[0], lo_v, color=c, alpha=0.06)\n",
    "    plt.fill_betweenx([y0, y1], hi_v, bin_edges[-1], color=c, alpha=0.06)\n",
    "\n",
    "plt.title(\"Histogram of brightness values across all tiles (NPZ)\")\n",
    "plt.xlabel(\"Raw intensity value\")\n",
    "plt.ylabel(\"Pixel count\" + (\" (log)\" if LOG_Y else \"\"))\n",
    "\n",
    "# compact legend: show each percentage once\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "seen, kept = set(), []\n",
    "for h, l in zip(handles, labels):\n",
    "    key = l.split()[0]  # \"0.5%\", \"1%\", \"5%\"\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        kept.append((h, l))\n",
    "plt.legend(*zip(*kept), loc=\"upper right\", frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print exact thresholds\n",
    "for p, lo_v, hi_v in clip_vals:\n",
    "    print(f\"{fmt_pct(p)}% clip → lo={int(round(lo_v))}, hi={int(round(hi_v))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c82ec0-6972-44e2-827d-21c0955e858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_downsampled_mosaic_h5(\n",
    "    df,\n",
    "    num_tiles: int = 40,\n",
    "    max_canvas_px: int = 5000,\n",
    "    px_per_um_target: float | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a downsampled RGB mosaic from the first `num_tiles` tiles in `df`.\n",
    "\n",
    "    Uses:\n",
    "        - width_px, height_px, px_x_um, px_y_um\n",
    "        - stage_x_um, stage_y_um  → X_rel_um, Y_rel_um\n",
    "        - npz_path\n",
    "        - norm_thumb_from_row(row)  -> PIL RGB thumbnail (handles grayscale)\n",
    "\n",
    "    Returns:\n",
    "        merged_rgb : uint8 (H, W, 3)\n",
    "        extent     : [xmin, xmax, ymin, ymax] in µm\n",
    "    \"\"\"\n",
    "    # work on a copy\n",
    "    D = df.copy()\n",
    "\n",
    "    # --- ensure tile sizes in µm exist (same logic as rectangle / overlay cells) ---\n",
    "    if (\"TileWidth_um\" not in D.columns) or D[\"TileWidth_um\"].isna().any():\n",
    "        if {\"width_px\", \"px_x_um\"}.issubset(D.columns):\n",
    "            D[\"TileWidth_um\"] = D.get(\"TileWidth_um\")\n",
    "            m = D[\"TileWidth_um\"].isna()\n",
    "            D.loc[m, \"TileWidth_um\"] = D.loc[m, \"width_px\"] * D.loc[m, \"px_x_um\"]\n",
    "        else:\n",
    "            raise ValueError(\"Need either TileWidth_um or (width_px, px_x_um) in site_df.\")\n",
    "\n",
    "    if (\"TileHeight_um\" not in D.columns) or D[\"TileHeight_um\"].isna().any():\n",
    "        if {\"height_px\", \"px_y_um\"}.issubset(D.columns):\n",
    "            D[\"TileHeight_um\"] = D.get(\"TileHeight_um\")\n",
    "            m = D[\"TileHeight_um\"].isna()\n",
    "            D.loc[m, \"TileHeight_um\"] = D.loc[m, \"height_px\"] * D.loc[m, \"px_y_um\"]\n",
    "        else:\n",
    "            raise ValueError(\"Need either TileHeight_um or (height_px, px_y_um) in site_df.\")\n",
    "\n",
    "    # --- ensure relative coords in µm exist ---\n",
    "    if (\n",
    "        (\"X_rel_um\" not in D.columns)\n",
    "        or (\"Y_rel_um\" not in D.columns)\n",
    "        or D[\"X_rel_um\"].isna().any()\n",
    "        or D[\"Y_rel_um\"].isna().any()\n",
    "    ):\n",
    "        x0 = float(D[\"stage_x_um\"].min())\n",
    "        y0 = float(D[\"stage_y_um\"].min())\n",
    "        D[\"X_rel_um\"] = D[\"stage_x_um\"] - x0\n",
    "        D[\"Y_rel_um\"] = D[\"stage_y_um\"] - y0\n",
    "\n",
    "    # --- keep only rows with complete geometry + npz_path ---\n",
    "    if \"npz_path\" not in D.columns:\n",
    "        raise ValueError(\"Need 'npz_path' column in site_df to build mosaic.\")\n",
    "    geom_cols = [\"X_rel_um\", \"Y_rel_um\", \"TileWidth_um\", \"TileHeight_um\", \"npz_path\"]\n",
    "    Dm = D.dropna(subset=geom_cols).copy()\n",
    "    Dm = Dm.head(num_tiles)\n",
    "\n",
    "    if Dm.empty:\n",
    "        raise ValueError(\"No tiles with geometry/npz info to build a mosaic from.\")\n",
    "\n",
    "    # --- spatial bounding box in µm ---\n",
    "    x_min = float(Dm[\"X_rel_um\"].min())\n",
    "    x_max = float((Dm[\"X_rel_um\"] + Dm[\"TileWidth_um\"]).max())\n",
    "    y_min = float(Dm[\"Y_rel_um\"].min())\n",
    "    y_max = float((Dm[\"Y_rel_um\"] + Dm[\"TileHeight_um\"]).max())\n",
    "\n",
    "    width_um  = x_max - x_min\n",
    "    height_um = y_max - y_min\n",
    "    longest_um = max(width_um, height_um)\n",
    "    if longest_um <= 0:\n",
    "        raise ValueError(\"Degenerate extent (width/height in µm is zero).\")\n",
    "\n",
    "    # --- choose pixels-per-micron for the canvas ---\n",
    "    if px_per_um_target is not None:\n",
    "        px_per_um = float(px_per_um_target)\n",
    "        if longest_um * px_per_um > max_canvas_px:\n",
    "            px_per_um = max_canvas_px / longest_um\n",
    "    else:\n",
    "        px_per_um = max_canvas_px / longest_um\n",
    "\n",
    "    canvas_w = max(1, int(round(width_um  * px_per_um)))\n",
    "    canvas_h = max(1, int(round(height_um * px_per_um)))\n",
    "    canvas = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)\n",
    "\n",
    "    # --- paste each tile ---\n",
    "    for _, row in Dm.iterrows():\n",
    "        # already handles grayscale → RGB\n",
    "        img = norm_thumb_from_row(row, max_side=1024)\n",
    "\n",
    "        tw_um = float(row[\"TileWidth_um\"])\n",
    "        th_um = float(row[\"TileHeight_um\"])\n",
    "        tw_px = max(1, int(round(tw_um * px_per_um)))\n",
    "        th_px = max(1, int(round(th_um * px_per_um)))\n",
    "\n",
    "        img_resized = img.resize((tw_px, th_px), Image.BILINEAR)\n",
    "        tile = np.asarray(img_resized, dtype=np.uint8)\n",
    "\n",
    "        if tile.ndim == 2:  # just in case we ever get raw grayscale here\n",
    "            tile = np.repeat(tile[..., None], 3, axis=2)\n",
    "\n",
    "        x_um = float(row[\"X_rel_um\"]) - x_min\n",
    "        y_um = float(row[\"Y_rel_um\"]) - y_min\n",
    "\n",
    "        x0_px = int(round(x_um * px_per_um))\n",
    "        y0_px = int(round(y_um * px_per_um))\n",
    "        x1_px = min(canvas_w, x0_px + tw_px)\n",
    "        y1_px = min(canvas_h, y0_px + th_px)\n",
    "\n",
    "        if x1_px <= x0_px or y1_px <= y0_px:\n",
    "            continue\n",
    "\n",
    "        canvas[y0_px:y1_px, x0_px:x1_px, :] = tile[: (y1_px - y0_px), : (x1_px - x0_px), :]\n",
    "\n",
    "    merged_rgb = canvas\n",
    "    extent = [x_min, x_max, y_min, y_max]\n",
    "\n",
    "    # optional: save mosaic PNG next to summary_table/config.txt\n",
    "    try:\n",
    "        outpath = os.path.join(out_dir, f\"merged_first{len(Dm)}.png\")\n",
    "        Image.fromarray(merged_rgb, mode=\"RGB\").save(outpath)\n",
    "        print(f\"Saved downsampled mosaic to: {os.path.abspath(outpath)}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not save mosaic PNG:\", e)\n",
    "\n",
    "    print(f\"Canvas: {merged_rgb.shape[1]}x{merged_rgb.shape[0]} px, px/µm ≈ {px_per_um:.4f}\")\n",
    "    return merged_rgb, extent\n",
    "\n",
    "# ---- run it on your h5 data ----\n",
    "NUM_TILES_FOR_MOSAIC = 40\n",
    "merged_rgb, extent = build_downsampled_mosaic_h5(site_df, num_tiles=NUM_TILES_FOR_MOSAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108c46f-0564-4710-9d07-fe9fde7f014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# ---------- figure ----------\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "ax.set_title(\"Zoom (toolbar) to inspect, then LEFT-click two points → Process\")\n",
    "im = ax.imshow(merged_rgb, extent=extent, origin='upper')\n",
    "ax.set_xlabel(\"X (µm)\")\n",
    "ax.set_ylabel(\"Y (µm)\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# visuals for picks\n",
    "p1_artist, = ax.plot([], [], 'o', ms=8, label=\"P1\")\n",
    "p2_artist, = ax.plot([], [], 'o', ms=8, label=\"P2\")\n",
    "line_artist, = ax.plot([], [], '-', lw=2, label=\"P1–P2\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "picked = []   # holds up to 2 tuples (x_um, y_um)\n",
    "\n",
    "# ---------- UI ----------\n",
    "btn_reset   = w.Button(description=\"Reset\",   button_style=\"warning\")\n",
    "btn_process = w.Button(description=\"Process\", button_style=\"success\")\n",
    "status_out  = w.Output(layout={\"border\":\"1px solid #ddd\"})\n",
    "display(w.HBox([btn_reset, btn_process]), status_out)\n",
    "\n",
    "outname = \"rotation.txt\"\n",
    "outpath = os.path.join(out_dir, outname)\n",
    "\n",
    "def _status(msg):\n",
    "    status_out.clear_output(wait=True)\n",
    "    with status_out:\n",
    "        print(msg)\n",
    "\n",
    "def reset(_btn=None):\n",
    "    picked.clear()\n",
    "    p1_artist.set_data([], [])\n",
    "    p2_artist.set_data([], [])\n",
    "    line_artist.set_data([], [])\n",
    "    fig.canvas.draw_idle()\n",
    "    _status(\"Cleared picks. Left-click two points, then press Process.\")\n",
    "\n",
    "btn_reset.on_click(reset)\n",
    "\n",
    "def rotation_to_horizontal_deg(angle_deg: float) -> float:\n",
    "    \"\"\"\n",
    "    Given the absolute segment angle (deg, CCW +X), return the smallest CCW rotation\n",
    "    in [-90, +90] deg that makes the segment horizontal (angle ≡ 0 mod 180).\n",
    "    \"\"\"\n",
    "    # Wrap angle to [-180, 180)\n",
    "    a = (angle_deg + 180) % 360 - 180\n",
    "    rot = -a                      # rotate so angle→0\n",
    "    if rot > 90:\n",
    "        rot -= 180\n",
    "    if rot <= -90:\n",
    "        rot += 180\n",
    "    return rot\n",
    "\n",
    "def process(_btn=None):\n",
    "    if len(picked) != 2:\n",
    "        _status(\"Need exactly two points. Left-click twice, then press Process.\")\n",
    "        return\n",
    "\n",
    "    (x1, y1), (x2, y2) = picked\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    dist = float(np.hypot(dx, dy))\n",
    "    if dist == 0:\n",
    "        _status(\"The two points coincide. Pick two distinct points.\")\n",
    "        return\n",
    "\n",
    "    # Angle of segment; origin='upper' means Y grows downward, but atan2(dy,dx) is correct.\n",
    "    angle_deg = float(np.degrees(np.arctan2(dy, dx)))\n",
    "    rot_deg = float(rotation_to_horizontal_deg(angle_deg))\n",
    "\n",
    "    # Write file\n",
    "    with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{rot_deg:.6f}\\n\")\n",
    "\n",
    "    config_path = out_dir / \"config.txt\"\n",
    "    with open(config_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"rotation={rot_deg:.6f}\\n\")\n",
    "\n",
    "    # Visual + status\n",
    "    _status(\n",
    "        f\"P1=({x1:.2f}, {y1:.2f}) µm | P2=({x2:.2f}, {y2:.2f}) µm\\n\"\n",
    "        f\"Δ=({dx:.2f}, {dy:.2f}) µm  | |Δ|={dist:.2f} µm  | angle={angle_deg:.2f}°\\n\"\n",
    "        f\"→ rotate by {rot_deg:.2f}° (CCW) to make the line horizontal\\n\"\n",
    "        f\"Wrote: {outpath}\"\n",
    "    )\n",
    "\n",
    "    # optional: copy to clipboard\n",
    "    payload = {\"P1_um\":[x1,y1], \"P2_um\":[x2,y2], \"angle_deg\":angle_deg, \"rotation_deg\":rot_deg}\n",
    "    try:\n",
    "        display(Javascript(f\"navigator.clipboard.writeText({repr(payload)})\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "btn_process.on_click(process)\n",
    "\n",
    "def onclick(event):\n",
    "    # Only inside axes, left button, and not while a toolbar tool is active\n",
    "    if event.inaxes is not ax:\n",
    "        return\n",
    "    if getattr(event, \"button\", 1) != 1:  # 1=left, 2=middle, 3=right\n",
    "        return\n",
    "    tb = getattr(fig.canvas, \"toolbar\", None)\n",
    "    if tb and getattr(tb, \"mode\", \"\"):\n",
    "        return\n",
    "\n",
    "    x, y = float(event.xdata), float(event.ydata)\n",
    "    if len(picked) == 0:\n",
    "        picked[:] = [(x, y)]\n",
    "        p1_artist.set_data([x], [y])\n",
    "        p2_artist.set_data([], [])\n",
    "        line_artist.set_data([], [])\n",
    "        _status(f\"Picked P1=({x:.2f}, {y:.2f}) µm. Pick P2, then press Process.\")\n",
    "    elif len(picked) == 1:\n",
    "        picked.append((x, y))\n",
    "        p2_artist.set_data([x], [y])\n",
    "        line_artist.set_data([picked[0][0], x], [picked[0][1], y])\n",
    "        _status(\"P1 and P2 selected. Press Process.\")\n",
    "    else:\n",
    "        picked[:] = [(x, y)]\n",
    "        p1_artist.set_data([x], [y])\n",
    "        p2_artist.set_data([], [])\n",
    "        line_artist.set_data([], [])\n",
    "        _status(f\"Restarted: P1=({x:.2f}, {y:.2f}) µm. Pick P2, then press Process.\")\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efcb49-9e32-475d-be3f-f55ffe6dea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------- loader (handles all variants we've seen) -------------------- #\n",
    "def _detect_channel_axis_3d(shape):\n",
    "    \"\"\"\n",
    "    Given a 3D shape, pick which axis is the spectral axis.\n",
    "\n",
    "    Heuristic based on formats we've seen:\n",
    "      - Channel length is typically 1024 or 2048.\n",
    "      - If multiple axes match {1024, 2048}, prefer the LAST one.\n",
    "      - If none match, fall back to the largest dimension.\n",
    "    \"\"\"\n",
    "    candidates = [i for i, d in enumerate(shape) if d in (1024, 2048)]\n",
    "    if len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "    elif len(candidates) > 1:\n",
    "        return max(candidates)  # prefer last occurrence (works for 1408,2048,1024)\n",
    "    else:\n",
    "        return int(np.argmax(shape))  # fallback\n",
    "\n",
    "def load_eds_array(p: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load an EDS array from an NPZ file.\n",
    "\n",
    "    Returns:\n",
    "      • 3D data as (H, W, C) with channels last, for any permutation\n",
    "        that contains a 1024/2048-like spectral axis (or falls back to\n",
    "        the largest axis).\n",
    "      • 2D data as-is for inputs that are (N_pixels, C).\n",
    "\n",
    "    Covers:\n",
    "      • legacy format  -> (C, H, W) or similar\n",
    "      • modern format  -> (H, W, C)\n",
    "      • flattened      -> (N_pixels, C)\n",
    "    \"\"\"\n",
    "    with np.load(p, allow_pickle=False) as z:\n",
    "        key = \"eds_data\" if \"eds_data\" in z.files else next(iter(z.files))\n",
    "        arr = np.asarray(z[key])\n",
    "\n",
    "    if arr.ndim == 3:\n",
    "        c_axis = _detect_channel_axis_3d(arr.shape)\n",
    "        if c_axis != 2:\n",
    "            arr = np.moveaxis(arr, c_axis, -1)  # -> (H, W, C)\n",
    "        return arr\n",
    "\n",
    "    elif arr.ndim == 2:\n",
    "        # (N_pixels, C) – we assume last axis is channels, which is what we want\n",
    "        return arr\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"{p.name}: expected 2D or 3D EDS array, got shape {arr.shape}\")\n",
    "\n",
    "\n",
    "# -------------------- choose which EDS file to plot -------------------- #\n",
    "n = 10  # <-- change this to select the nth *_eds.npz file (1-based index)\n",
    "\n",
    "root = Path(pythondata_folder)  # or h5pythondata_folder, depending on your notebook\n",
    "eds_files = sorted(root.rglob(\"*_eds.npz\"))\n",
    "print(f\"Found {len(eds_files)} EDS NPZ file(s) under {root}\")\n",
    "\n",
    "if not eds_files:\n",
    "    raise RuntimeError(\"No *_eds.npz files found; nothing to plot.\")\n",
    "\n",
    "if not (1 <= n <= len(eds_files)):\n",
    "    raise ValueError(f\"Requested n={n} but there are only {len(eds_files)} files.\")\n",
    "\n",
    "target_path = eds_files[n - 1]\n",
    "print(f\"Using file #{n}: {target_path}\")\n",
    "\n",
    "# -------------------- load and interpret -------------------- #\n",
    "arr = load_eds_array(target_path)\n",
    "print(\"Loaded array shape:\", arr.shape, \"dtype:\", arr.dtype)\n",
    "\n",
    "if arr.ndim == 3:\n",
    "    H, W, C = arr.shape\n",
    "    # map-sum spectrum\n",
    "    sum_spec = arr.reshape(-1, C).sum(axis=0).astype(float)\n",
    "    # center-pixel spectrum\n",
    "    cy, cx = H // 2, W // 2\n",
    "    one_pixel = arr[cy, cx, :].astype(float)\n",
    "\n",
    "elif arr.ndim == 2:\n",
    "    N, C = arr.shape\n",
    "    sum_spec = arr.sum(axis=0).astype(float)\n",
    "    one_pixel = arr[0, :].astype(float)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected ndim={arr.ndim} after loading EDS data.\")\n",
    "\n",
    "channels = np.arange(C)\n",
    "\n",
    "# -------------------- plot map-sum spectrum -------------------- #\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(channels, sum_spec)\n",
    "plt.xlabel(\"Channel index\")\n",
    "plt.ylabel(\"Total counts (sum over all pixels)\")\n",
    "plt.title(f\"EDS map-sum spectrum for file #{n}\\n{target_path.name}\")\n",
    "# plt.yscale(\"log\")  # uncomment if you want log scale\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- plot single-pixel spectrum -------------------- #\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(channels, one_pixel)\n",
    "plt.xlabel(\"Channel index\")\n",
    "plt.ylabel(\"Counts (single pixel)\")\n",
    "plt.title(f\"Single-pixel spectrum – file #{n}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619977cb-ac05-423d-aa6b-a4dde76f2446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
